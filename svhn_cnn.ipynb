{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svhn_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne8-VuEF5Kza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "d72b6a1d-bd17-422f-c845-2da2679f0eb4"
      },
      "source": [
        "!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
        "!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-10 14:03:29--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182040794 (174M) [text/plain]\n",
            "Saving to: ‘train_32x32.mat’\n",
            "\n",
            "train_32x32.mat     100%[===================>] 173.61M  19.8MB/s    in 11s     \n",
            "\n",
            "2020-05-10 14:03:41 (15.3 MB/s) - ‘train_32x32.mat’ saved [182040794/182040794]\n",
            "\n",
            "--2020-05-10 14:03:41--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64275384 (61M) [text/plain]\n",
            "Saving to: ‘test_32x32.mat’\n",
            "\n",
            "test_32x32.mat      100%[===================>]  61.30M  15.2MB/s    in 5.9s    \n",
            "\n",
            "2020-05-10 14:03:48 (10.4 MB/s) - ‘test_32x32.mat’ saved [64275384/64275384]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8thOShA5eD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import loadmat\n",
        "svhn_train = loadmat('train_32x32.mat')\n",
        "svhn_test = loadmat('test_32x32.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xob6xBA6KVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "d8d4e7aa-718a-4862-a19a-dad1dfec95c5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "svhn_x_train = svhn_train['X']\n",
        "svhn_y_train = svhn_train['y']\n",
        "svhn_x_test = svhn_test['X']\n",
        "svhn_y_test = svhn_test['y']\n",
        "display(svhn_x_train.shape)\n",
        "display(svhn_y_train.shape)\n",
        "plt.imshow(svhn_x_test[:,:,:,0])\n",
        "display(svhn_y_train[0])\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(32, 32, 3, 73257)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(73257, 1)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYcklEQVR4nO2db4hkZXbGn3Pvreru+QOr0QzDKKu7EYIs2VGawbCymF12MbKgkiD6QfwgO0tYIcLmgxiIBvLBDVHxk2GMw84G45+sikOQZI0syH5xbY2Oo5Psqoyswzij6OIYp7uqbp18qDukZ7jn6erbVbdG3+cHTVfft973PfXee/pWvU+dc8zdIYT44pPN2gAhRDvI2YVIBDm7EIkgZxciEeTsQiSCnF2IRCg20tnMrgbwAIAcwD+5+z3s+fl8xztb54PBGszPGpmiaHHPxmOeNTRYyLOGeIHp6Wz0mpvN1XTMSRNJ5v1PV1Au92sXxJrq7GaWA/g1gO8AeA/ASwBucvc3oz7z52/1L//Zzmg8Nlvt0Yyc5MyJQ1v8hoZZkYVLtX7bp4a392Zt0l/RYNciOZ1rXDvhiMSOIekVt5Vehm3URqsfk/Upe/3a44f3H8Dyh5/WdtzIlbELwFvu/o679wA8BuDaDYwnhJgiG3H2HQB+u+rv96pjQoizkA19Zh8HM9sNYDcAFFvmpj2dECJgI3f2IwAuXPX3BdWx03D3Pe6+6O6L+XxnA9MJITbCRpz9JQCXmNnFZtYFcCOA/ZMxSwgxaRq/jXf3gZndBuA/MJLe9rr7G7STNd05DWwgQ8V7pvw/XJt750Z2s9k6NVFQmq77kEzF1jE6N8x2ZiNdD2IHvxLWD5P5csuJFfFOfTjXcLJX44Y+s7v7swCenZAtQogpom/QCZEIcnYhEkHOLkQiyNmFSAQ5uxCJMPVv0J2JBxIKk2SyLNJxmlrBot6ayT8RcfAMl/mcBfKwnoFc0+/14i5k7Zn6w15bGTQ2DZ5h10enE39ZKy/q5TAnF4+xeyAJkqGXh8eyXCgPMm25wX1ad3YhEkHOLkQiyNmFSAQ5uxCJIGcXIhFa342PaLLTHe3sA2vtqMb9ekG6HwDor6zUHh+W8Q5tQdJEFXm8/DlpYwE05WBQe/zT/z0Z9mG78SVLwzSI12oY7FpbFq9H3o131YsiXo/NmzbFYwa78XnOdsdJ0E0ZB7QMgrUHuAqRF/VrkhXdsE8Z2MGUGt3ZhUgEObsQiSBnFyIR5OxCJIKcXYhEkLMLkQgzkN7qpYEm0huT1zJS9aXfiyWSleV6eQ0AeieXa4+XK7EEVRAbO0ROYvazxHBlIAMuL5NAmHgmWuVkUMbrOIz65fHr6pK5hsNYlltYCEqKgV1XRAtjlWloJA8LoiLdGtxzPch3x6zTnV2IRJCzC5EIcnYhEkHOLkQiyNmFSAQ5uxCJsCHpzcwOAzgBoAQwcPfFNXrAmKQU9qrvYzRPWzzPoB9LRj0iUa2crJfl+oEkBwAZkclYuSDWxtQfD+ajEYIkEo3RKF8fjVRsOhfr2CTpHRmQlqiKuzmLpAva6HkOr/14nkno7H/i7h9OYBwhxBTR23ghEmGjzu4Afm5mL5vZ7kkYJISYDht9G3+lux8xs98H8JyZ/be7v7D6CdU/gd0AUGyZ2+B0QoimbOjO7u5Hqt/HATwNYFfNc/a4+6K7L+YLcZodIcR0aezsZrbZzLaeegzguwAOTsowIcRk2cjb+G0Anq4klgLAv7j7v7MOhmZRSJHExmQ8mnCSyBPDYRwDFkl2fRL1hkE8HpPXCiOnhilDwTJ25uKPUKzKUJHFNjI5zINzY0ECSAAoSBmnoksScAYJGwEgyvfppIwT09A8KkW2Rj8aSRccZ6W3wjym7FzGTRx3fwfA15v2F0K0i6Q3IRJBzi5EIsjZhUgEObsQiSBnFyIRWk84GStv66/NZkQGycj/sYJIdqwtCzWSsAtIDkUuoXWaJi+sp9OJT/UwfGFARqQyVi3NLVgUIpN1SK23vBvPljHpLRC2ouMAj74Dk95ogB2ReyNZjsiDwwa3ad3ZhUgEObsQiSBnFyIR5OxCJIKcXYhEaL/8U7TrToJCot3njEQKZDTXGenH8tpFthM7WJ68PI9fcyeLTw3rF+0Wz5FAGORkPTrxXEOy/exRRA4xPZ9jO+6kjZSUsqx+R3tIcgMOab47suVOlBy2VlFTUMnrlCGksR7d2YVIBDm7EIkgZxciEeTsQiSCnF2IRJCzC5EILUtvFsoTVA6LZAamghArSNwHlcqi4BoWdMNeVzeLs+3Od2KprNuN27IgYGR+80LYx4j0Zh2W3y3WhspI2spJAEocBwMr4kuVBcIMA6lsSKKXhiQAheU2ZIFZ7IKMAmFYXE0YO0P66M4uRCLI2YVIBDm7EIkgZxciEeTsQiSCnF2IRFhTejOzvQC+B+C4u3+tOnYugMcBXATgMIAb3P3jNWczxNIbifDJAt2CKx0k2oxElBUZKUEUlEIqchKhRmycn4ult82bNodtc/Ox9BaVUMrmiK5FItFYLjwnGmYZJN8bshPNktqRyDZWkmkY2cEi9lhSQabpMgmTlZQKSoQxG8tQHiT5BMOW/+cnAK4+49gdAJ5390sAPF/9LYQ4i1nT2at66x+dcfhaAPuqx/sAXDdhu4QQE6bpZ/Zt7n60evw+RhVdhRBnMRveoHN3B/mgYGa7zWzJzJYGJ3sbnU4I0ZCmzn7MzLYDQPX7ePREd9/j7ovuvlgsxBtSQojp0tTZ9wO4pXp8C4BnJmOOEGJajCO9PQrgKgDnmdl7AO4CcA+AJ8zsVgDvArhh46YwHS0o/0RGY5FoGUlumQXyGmsrqJRHyh114nc63e582LYwvylsy4MEkSWRk0omvTWI1gIQf7Bj49EkimyuBpIXOS/OXhe9PcZrzIaM1pGubyR7kiVc09nd/aag6dtr9RVCnD3oG3RCJIKcXYhEkLMLkQhydiESQc4uRCK0X+stgEUFRW2snltGXlqGfjwXrfMVROyx8DsiC7HaYM6ipNZf5gudIBoOAJDVR4YBcdQYwOWk6LUxaRO0jhqpzUaXuL6xY/H1wV4Wm2tYxms1GAzCtjIo6jYsm9QJZD4hhEgCObsQiSBnFyIR5OxCJIKcXYhEkLMLkQhnjfTGBI8oConWwiKtTCqLJQ0giyKlWMLDkkhGLBJqGEdQ9Qfrl8rKAUleCDIeqec2ZDJPtIxOohFZHTUqNxKZMmxgEWVMSmXyIOlHEmZG55om0mwgv+rOLkQiyNmFSAQ5uxCJIGcXIhHk7EIkQuu78dGGtpHtxSgGguUKGyIOPGBBCf1+HCTTW6lPhb28vBL2YZWEnES0MKWhR+y3IDcZC54ZsNxptFxTfK/Ig7JRGUl417U4WCcjef7IBn/4wqmSQ64rFiiFsCQTYGzMaNe9ScQTQXd2IRJBzi5EIsjZhUgEObsQiSBnFyIR5OxCJMI45Z/2AvgegOPu/rXq2N0Avg/gg+ppd7r7s+NMGJfjIWJIFKfBKgIRqYPJayu95bCt16+X3th4wyC/GMClN0ZvQHLoBevrZH2HRHobkiAZJr0V3XqJreNxyStSlQtFvv7cgACRykj5J1pOigSnZCxwhQQ2dQL7SxKUNaTiYT3j3Nl/AuDqmuP3u/vO6mcsRxdCzI41nd3dXwDwUQu2CCGmyEY+s99mZgfMbK+ZnTMxi4QQU6Gpsz8I4KsAdgI4CuDe6IlmttvMlsxsqTxZ/5lXCDF9Gjm7ux9z99LdhwAeArCLPHePuy+6+2K+EG/OCCGmSyNnN7Ptq/68HsDByZgjhJgW40hvjwK4CsB5ZvYegLsAXGVmOzESvw4D+ME4k5kRxYPW8Am6sNJENPcbk5piIkWGKmhM4iFy0oCUOzJWJimQZAY9Un7ISYQgWWNWsqszqH/dQyIBZp1YajJSvipnud+iJhLNx3LhsQvEiByWk7JXgyAZIY+wW7/0tqazu/tNNYcfXvdMQoiZom/QCZEIcnYhEkHOLkQiyNmFSAQ5uxCJ0HLCSYtLKBE5zAOpiUW2OYkyKss4aoy1hZFLRPphkVwkWAt5Hp+ajERDeSDjULGOyJ4DUmoqOi8AMAxeuBEJsCCJNFmbEQkzC7JRGotsa6DkjdoaRN8BoQxI1GMWixiiO7sQiSBnFyIR5OxCJIKcXYhEkLMLkQhydiESoVXpzQBkUUJEond4JBwRaYJFxA1o1BuR8wKpiUk/RqLeirk4kqvokrYilt6i9S2H8XqwSD8riSxXxnJYpA2VJbGDyHyDPpHlSLQchlFxwbgLuwWySD8Kq/UWjMmSW4KsY4Tu7EIkgpxdiESQswuRCHJ2IRJBzi5EIrQcCBPDgwiCvGpk55yVNMoLVrYoXpJirr5tSAJCOkU83sL8Qtg2vzBPxox36qMAj15vJezDSjyx0krRzj+AcPeZBS+xEklOFBRKZCOPDCJ2sI4kIIdcI9F0dN9//SnodGcXIhXk7EIkgpxdiESQswuRCHJ2IRJBzi5EIoxT/ulCAD8FsA2jDf897v6AmZ0L4HEAF2FUAuoGd/+4qSEZKY+DIggUYPnRBrE2URJZzvO4X3dTfWHKhc2xhMakt243LnTJZLluEfcbBonLciKhnTjxSdg26Mc5+UhauDCopb8SV/IdzsevKyfJ/AqSry9qY/nznARR0bJLTCsj/fI8yJNH7sWdIG8gU0PHubMPAPzI3S8FcAWAH5rZpQDuAPC8u18C4PnqbyHEWcqazu7uR939lerxCQCHAOwAcC2AfdXT9gG4blpGCiE2zro+s5vZRQAuA/AigG3ufrRqeh+jt/lCiLOUsZ3dzLYAeBLA7e5+2oc8H32HsPZDiZntNrMlM1sanIw/rwkhpstYzm5mHYwc/RF3f6o6fMzMtlft2wEcr+vr7nvcfdHdF4uFeANGCDFd1nR2G+XMeRjAIXe/b1XTfgC3VI9vAfDM5M0TQkyKcaLevgHgZgCvm9mr1bE7AdwD4AkzuxXAuwBuGGvGqOwOy7cVaBpO+kSpxwAg75Cot2EcUebBanVJTrhOHo/HZLm5edKPSE1lJHn1WIkqEnFIFFGSXi8sXcRyuLF8fZE8BQAFKYcVSY5lUHIJ4JF+LNyMxsORazVyiSjaEwCMSIcRazq7u/8SsYL47XXPKISYCfoGnRCJIGcXIhHk7EIkgpxdiESQswuRCDNIOBnIaA3K4zC5jslCrLQSG9MDPalDpB8mk1HJiMiDvCxQ/eFBGUevsVJZLJIrI3JYFnTM2WtmbSQqkpZkikp2MemK5dHkoW3NxgylNzJcgypUurMLkQhydiESQc4uRCLI2YVIBDm7EIkgZxciEc6aWm+MSJbLib5mpB4aSFJJJvF4UIusIHYUrFYakZpAI6+IPDisf229Xpw4ZFDGmSM90oXApTcEL43V0mORbUxeyxpEy7HacSyejNW3I0vFpeVAL/WG0XcRurMLkQhydiESQc4uRCLI2YVIBDm7EInwud6NZwEhBckLl5FdzjKLd6aHwU43243Pyc45zcfWcGd3EAS1fLa8HPbp9+PXXLJdXxYIE5Tsytl5YdFLBHY+o7x2GbnPDUl5MBrrQs8ZG7N+UG+w487QnV2IRJCzC5EIcnYhEkHOLkQiyNmFSAQ5uxCJsKb0ZmYXAvgpRiWZHcAed3/AzO4G8H0AH1RPvdPdn21qSBTAUbXWHmVBCSzIpCB54VhwzXBYL2vlpEYSk96i8QDASY60YRCQAwD9sn7M5X4cCFMOSEkjssY5KV9VBDn0ig6R3kgbL1G1/uuAi1rxeaHnjEiiPEiGGlMLzbsXMI7OPgDwI3d/xcy2AnjZzJ6r2u53939Y96xCiNYZp9bbUQBHq8cnzOwQgB3TNkwIMVnW9ZndzC4CcBmAF6tDt5nZATPba2bnTNg2IcQEGdvZzWwLgCcB3O7unwB4EMBXAezE6M5/b9Bvt5ktmdnS4LP4c6MQYrqM5exm1sHI0R9x96cAwN2PuXvpoy/9PgRgV11fd9/j7ovuvlhs6k7KbiHEOlnT2W207fcwgEPuft+q49tXPe16AAcnb54QYlKMsxv/DQA3A3jdzF6tjt0J4CYz24mRinEYwA/GmTCSDHgJokCbYLJQlAQNPLqKSSu0Hk9ASSRFLuPE8hpJGYdeILGxSK4heV15Ea9VpxPn+Zubr7+0OnNxn2IufufHSnZlJJIukuyMrK8RnYxJXkOWGzBsiduYlNeEcXbjf4n6y7yxpi6EaB99g06IRJCzC5EIcnYhEkHOLkQiyNmFSIQZJJyMZDSSkC+QNFjUW0Gi3gYkwWKvtxK2RVKZsf+ZRHob9Ptkrng9Bv247eRnQWJJlpSRlsOK+80Rqaw7X9/GpLf5ufl4rmA8gMuDCCLibMjOGSkNRaW3hgTLz4S3SAJk6rDu7EIkgpxdiESQswuRCHJ2IRJBzi5EIsjZhUiE9qW3KIKNZeQLYNIEk65WVk6GbSdPxjXRojGZ5SyR5mBAaqwFiSMBoN+L23rL9XIey0+YkWSOeYcklaQRbPVtBRuPJLDMslhKXaPIWtRAxmNTkYg4cg0zWa7BpR9eV8wndGcXIhHk7EIkgpxdiESQswuRCHJ2IRJBzi5EIrQrvVksXTDZJZK8VlbiCLVPV+Ic9YPluF8TOawcNKv/ZUQoKUuWcJIksQzm65fxesx1FsI2miCyG5+zuSBBZBQNB3AJcECScw56RNgKhnRWz61Resi16sexBKiB/U7uxYFeRyXWuEkI8UVCzi5EIsjZhUgEObsQiSBnFyIR1tyNN7N5AC8AmKue/zN3v8vMLgbwGIDfA/AygJvdnZdpdRJMwnJ7BX3YTreTQJge29kleeHKYKeeBa3Q3Xi2dUogBargwZ7w/MLmsE+XlFZiu+cdshufB21GSjVF+eIAwDJSWomsY1RGq0nwyWg80thwzGjXnZahahDfM86dfQXAt9z96xiVZ77azK4A8GMA97v7HwD4GMCtY4wlhJgRazq7j/i0+rNT/TiAbwH4WXV8H4DrpmKhEGIijFufPa8quB4H8ByAtwH8zt1Pva99D8CO6ZgohJgEYzm7u5fuvhPABQB2AfjDcScws91mtmRmS4OT/CO9EGJ6rGs33t1/B+AXAP4YwJfM7NQuzAUAjgR99rj7orsvFgvxZo8QYrqs6exmdr6Zfal6vADgOwAOYeT0f1497RYAz0zLSCHExhknEGY7gH1mlmP0z+EJd/83M3sTwGNm9ncA/gvAw2sN5HCaGy4i6jMo46AVJnlFEhoADAax9BaVjWLBM8yOnJSoykjZJabY5UFA0datsfRmZK6cyHJznbmwrejU98uYvEYCYZhURvO7rbsBcKKhMTvYuWa6XNiPjhetFSmJRkY7ZcgBAJfVHH8Ho8/vQojPAfoGnRCJIGcXIhHk7EIkgpxdiESQswuRCMblgglPZvYBgHerP88D8GFrk8fIjtORHafzebPjy+5+fl1Dq85+2sRmS+6+OJPJZYfsSNAOvY0XIhHk7EIkwiydfc8M516N7Dgd2XE6Xxg7ZvaZXQjRLnobL0QizMTZzexqM/sfM3vLzO6YhQ2VHYfN7HUze9XMllqcd6+ZHTezg6uOnWtmz5nZb6rf58zIjrvN7Ei1Jq+a2TUt2HGhmf3CzN40szfM7C+r462uCbGj1TUxs3kz+5WZvVbZ8bfV8YvN7MXKbx43s/UliHD3Vn8wKnr1NoCvAOgCeA3ApW3bUdlyGMB5M5j3mwAuB3Bw1bG/B3BH9fgOAD+ekR13A/irltdjO4DLq8dbAfwawKVtrwmxo9U1wShOdUv1uAPgRQBXAHgCwI3V8X8E8BfrGXcWd/ZdAN5y93d8lHr6MQDXzsCOmeHuLwD46IzD12KUuBNoKYFnYEfruPtRd3+lenwCo+QoO9DymhA7WsVHTDzJ6yycfQeA3676e5bJKh3Az83sZTPbPSMbTrHN3Y9Wj98HsG2GttxmZgeqt/lT/zixGjO7CKP8CS9ihmtyhh1Ay2syjSSvqW/QXenulwP4UwA/NLNvztogYPSfHWtVAJ4eDwL4KkY1Ao4CuLetic1sC4AnAdzu7p+sbmtzTWrsaH1NfANJXiNm4exHAFy46u8wWeW0cfcj1e/jAJ7GbDPvHDOz7QBQ/T4+CyPc/Vh1oQ0BPISW1sTMOhg52CPu/lR1uPU1qbNjVmtSzb3uJK8Rs3D2lwBcUu0sdgHcCGB/20aY2WYz23rqMYDvAjjIe02V/Rgl7gRmmMDzlHNVXI8W1sRGdbAeBnDI3e9b1dTqmkR2tL0mU0vy2tYO4xm7jddgtNP5NoC/npENX8FICXgNwBtt2gHgUYzeDvYx+ux1K0Y1854H8BsA/wng3BnZ8c8AXgdwACNn296CHVdi9Bb9AIBXq59r2l4TYkerawLgjzBK4noAo38sf7Pqmv0VgLcA/CuAufWMq2/QCZEIqW/QCZEMcnYhEkHOLkQiyNmFSAQ5uxCJIGcXIhHk7EIkgpxdiET4PzVGL1QXmomFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "horzYlVFcrbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "54532976-e0ce-4086-b686-be6bd469af50"
      },
      "source": [
        "import numpy as np\n",
        "x_train = svhn_x_train\n",
        "x_test = svhn_x_test\n",
        "y_test = svhn_y_test\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "x_train = np.moveaxis(x_train, 3, 0)\n",
        "x_test = np.moveaxis(x_test, 3, 0)\n",
        "display(x_train.shape)\n",
        "plt.imshow(x_train[0]+1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(73257, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fecea2f7c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdomrpL7Zscr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dd3abec2-fb1a-4565-e874-b563458865b3"
      },
      "source": [
        "import keras\n",
        "y_train = svhn_y_train[:,:]-1\n",
        "y_test = svhn_y_test[:,:]-1\n",
        "y_train_categorical = keras.utils.to_categorical(y_train)\n",
        "y_test_categorical = keras.utils.to_categorical(y_test)\n",
        "display(y_train_categorical.shape)\n",
        "display(y_test_categorical.shape)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(73257, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(26032, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcPnUdwoOEye",
        "colab_type": "code",
        "outputId": "a6ff6e50-8b48-4fff-b212-7398ccccc14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import models, layers, regularizers, optimizers\n",
        "\n",
        "def make_model1():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(filters=16,kernel_size=3,padding='same',activation='relu',input_shape=(32,32,3)))\n",
        "  model.add(layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(500,activation='relu'))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "  model.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "def make_model2():\n",
        "  base_hidden_units = 32\n",
        "  weight_decay = 1e-4\n",
        "  model = models.Sequential()\n",
        "\n",
        "  # CONV1\n",
        "  model.add(\n",
        "    layers.Conv2D(\n",
        "      base_hidden_units,\n",
        "      kernel_size=3,\n",
        "      padding='same',\n",
        "      kernel_regularizer = regularizers.l2(weight_decay),\n",
        "      input_shape=x_train.shape[1:4]\n",
        "    )\n",
        "  )\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  # CONV2\n",
        "  model.add(\n",
        "    layers.Conv2D(\n",
        "      base_hidden_units,\n",
        "      kernel_size=3,\n",
        "      padding='same',\n",
        "      kernel_regularizer=regularizers.l2(weight_decay)\n",
        "    )\n",
        "  )\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  # POOL + Dropout\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "\n",
        "  # CONV3\n",
        "  model.add(\n",
        "    layers.Conv2D(\n",
        "      base_hidden_units*2,\n",
        "      kernel_size=3,\n",
        "      padding='same',\n",
        "      kernel_regularizer=regularizers.l2(weight_decay)\n",
        "    )\n",
        "  )\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  # CONV4\n",
        "  model.add(\n",
        "    layers.Conv2D(\n",
        "      base_hidden_units*2,\n",
        "      kernel_size=3,\n",
        "      padding='same',\n",
        "      kernel_regularizer=regularizers.l2(weight_decay)\n",
        "    )\n",
        "  )\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  # POOL + Dropout\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  # Conv5\n",
        "  model.add(\n",
        "    layers.Conv2D(\n",
        "      base_hidden_units*4,\n",
        "      kernel_size=3,\n",
        "      padding='same',\n",
        "      kernel_regularizer=regularizers.l2(weight_decay)\n",
        "    )\n",
        "  )\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  # Conv6\n",
        "  model.add(\n",
        "    layers.Conv2D(\n",
        "      base_hidden_units*4,\n",
        "      kernel_size=3,\n",
        "      padding='same',\n",
        "      kernel_regularizer=regularizers.l2(weight_decay)\n",
        "    )\n",
        "  )\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  # layer 7: Fully Connected\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "model = make_model2()\n",
        "display(model.summary())\n",
        "optimizer=optimizers.adam(learning_rate=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANT-dT6FWZ0N",
        "colab_type": "code",
        "outputId": "89c21710-769b-4766-8456-72935ad7e5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import callbacks, preprocessing\n",
        "batch_size=128\n",
        "checkpointer=callbacks.ModelCheckpoint(filepath='model.weights.best.hdf5',verbose=1,save_best_only=True)\n",
        "n_validation_samples=5000\n",
        "display(x_train.shape[0])\n",
        "datagen = preprocessing.image.ImageDataGenerator(\n",
        "  rotation_range=15,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  horizontal_flip=True,\n",
        "  vertical_flip=False\n",
        ")\n",
        "# compute the data augmentation on the training set\n",
        "datagen.fit(x_train)\n",
        "hist=model.fit_generator(\n",
        "    generator=datagen.flow(\n",
        "        x_train[n_validation_samples:],\n",
        "        y_train_categorical[n_validation_samples:],\n",
        "        batch_size=batch_size\n",
        "    ),\n",
        "    validation_data=(x_train[:n_validation_samples],y_train_categorical[:n_validation_samples]),\n",
        "    steps_per_epoch=(x_train.shape[0] // batch_size),\n",
        "    epochs=125,\n",
        "    callbacks=[checkpointer],\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "73257"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            " - 61s - loss: 2.8494 - accuracy: 0.1987 - val_loss: 1.8235 - val_accuracy: 0.3820\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.82346, saving model to model.weights.best.hdf5\n",
            "Epoch 2/125\n",
            " - 53s - loss: 2.0764 - accuracy: 0.3679 - val_loss: 1.3121 - val_accuracy: 0.5738\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.82346 to 1.31213, saving model to model.weights.best.hdf5\n",
            "Epoch 3/125\n",
            " - 54s - loss: 1.7054 - accuracy: 0.4692 - val_loss: 0.9873 - val_accuracy: 0.6864\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.31213 to 0.98728, saving model to model.weights.best.hdf5\n",
            "Epoch 4/125\n",
            " - 53s - loss: 1.4177 - accuracy: 0.5576 - val_loss: 0.8115 - val_accuracy: 0.7566\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.98728 to 0.81153, saving model to model.weights.best.hdf5\n",
            "Epoch 5/125\n",
            " - 54s - loss: 1.2112 - accuracy: 0.6190 - val_loss: 0.6658 - val_accuracy: 0.8012\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.81153 to 0.66577, saving model to model.weights.best.hdf5\n",
            "Epoch 6/125\n",
            " - 54s - loss: 1.0663 - accuracy: 0.6673 - val_loss: 0.5830 - val_accuracy: 0.8286\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.66577 to 0.58304, saving model to model.weights.best.hdf5\n",
            "Epoch 7/125\n",
            " - 54s - loss: 0.9554 - accuracy: 0.7007 - val_loss: 0.5280 - val_accuracy: 0.8466\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.58304 to 0.52802, saving model to model.weights.best.hdf5\n",
            "Epoch 8/125\n",
            " - 54s - loss: 0.8570 - accuracy: 0.7333 - val_loss: 0.4846 - val_accuracy: 0.8624\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.52802 to 0.48461, saving model to model.weights.best.hdf5\n",
            "Epoch 9/125\n",
            " - 54s - loss: 0.7837 - accuracy: 0.7579 - val_loss: 0.4567 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.48461 to 0.45675, saving model to model.weights.best.hdf5\n",
            "Epoch 10/125\n",
            " - 54s - loss: 0.7267 - accuracy: 0.7772 - val_loss: 0.4180 - val_accuracy: 0.8810\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.45675 to 0.41796, saving model to model.weights.best.hdf5\n",
            "Epoch 11/125\n",
            " - 53s - loss: 0.6833 - accuracy: 0.7906 - val_loss: 0.3914 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.41796 to 0.39136, saving model to model.weights.best.hdf5\n",
            "Epoch 12/125\n",
            " - 53s - loss: 0.6410 - accuracy: 0.8061 - val_loss: 0.3795 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.39136 to 0.37948, saving model to model.weights.best.hdf5\n",
            "Epoch 13/125\n",
            " - 53s - loss: 0.6145 - accuracy: 0.8159 - val_loss: 0.3749 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.37948 to 0.37493, saving model to model.weights.best.hdf5\n",
            "Epoch 14/125\n",
            " - 52s - loss: 0.5874 - accuracy: 0.8262 - val_loss: 0.3595 - val_accuracy: 0.9014\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.37493 to 0.35952, saving model to model.weights.best.hdf5\n",
            "Epoch 15/125\n",
            " - 52s - loss: 0.5632 - accuracy: 0.8343 - val_loss: 0.3395 - val_accuracy: 0.9092\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.35952 to 0.33946, saving model to model.weights.best.hdf5\n",
            "Epoch 16/125\n",
            " - 52s - loss: 0.5460 - accuracy: 0.8389 - val_loss: 0.3332 - val_accuracy: 0.9106\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.33946 to 0.33318, saving model to model.weights.best.hdf5\n",
            "Epoch 17/125\n",
            " - 52s - loss: 0.5241 - accuracy: 0.8463 - val_loss: 0.3242 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.33318 to 0.32425, saving model to model.weights.best.hdf5\n",
            "Epoch 18/125\n",
            " - 52s - loss: 0.5120 - accuracy: 0.8516 - val_loss: 0.3225 - val_accuracy: 0.9132\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.32425 to 0.32252, saving model to model.weights.best.hdf5\n",
            "Epoch 19/125\n",
            " - 54s - loss: 0.4951 - accuracy: 0.8563 - val_loss: 0.3204 - val_accuracy: 0.9144\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.32252 to 0.32041, saving model to model.weights.best.hdf5\n",
            "Epoch 20/125\n",
            " - 53s - loss: 0.4830 - accuracy: 0.8603 - val_loss: 0.3148 - val_accuracy: 0.9152\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.32041 to 0.31475, saving model to model.weights.best.hdf5\n",
            "Epoch 21/125\n",
            " - 52s - loss: 0.4757 - accuracy: 0.8633 - val_loss: 0.3050 - val_accuracy: 0.9174\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.31475 to 0.30501, saving model to model.weights.best.hdf5\n",
            "Epoch 22/125\n",
            " - 52s - loss: 0.4611 - accuracy: 0.8686 - val_loss: 0.3032 - val_accuracy: 0.9222\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.30501 to 0.30322, saving model to model.weights.best.hdf5\n",
            "Epoch 23/125\n",
            " - 52s - loss: 0.4555 - accuracy: 0.8705 - val_loss: 0.2998 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.30322 to 0.29979, saving model to model.weights.best.hdf5\n",
            "Epoch 24/125\n",
            " - 53s - loss: 0.4458 - accuracy: 0.8724 - val_loss: 0.2929 - val_accuracy: 0.9256\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.29979 to 0.29293, saving model to model.weights.best.hdf5\n",
            "Epoch 25/125\n",
            " - 53s - loss: 0.4327 - accuracy: 0.8774 - val_loss: 0.2932 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.29293\n",
            "Epoch 26/125\n",
            " - 53s - loss: 0.4261 - accuracy: 0.8802 - val_loss: 0.2844 - val_accuracy: 0.9248\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.29293 to 0.28437, saving model to model.weights.best.hdf5\n",
            "Epoch 27/125\n",
            " - 53s - loss: 0.4243 - accuracy: 0.8803 - val_loss: 0.2906 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.28437\n",
            "Epoch 28/125\n",
            " - 53s - loss: 0.4135 - accuracy: 0.8834 - val_loss: 0.2846 - val_accuracy: 0.9246\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.28437\n",
            "Epoch 29/125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-2495cb4ecc86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RbqYOcb4gXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('temp_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7TIzPom3UGo",
        "colab_type": "code",
        "outputId": "30ea282b-abc1-4009-ef8e-e5fd0788ba3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "plt.plot(hist.history['val_accuracy'])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-0f83bfd2217b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBCuegh76dyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "51a08226-cc6e-4af0-d997-899c73b12662"
      },
      "source": [
        "model.load_weights('model.weights.best.hdf5')\n",
        "score = model.evaluate(x_test, y_test_categorical, verbose=1)\n",
        "score\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26032/26032 [==============================] - 9s 364us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2792073027187868, 0.9326213598251343]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-WIpfqZNhva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}